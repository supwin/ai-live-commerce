# app/services/ai_video_service.py
"""
AI Video Generation Service - Step 1 Implementation
‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏≤‡∏Å AI scripts ‡∏û‡∏£‡πâ‡∏≠‡∏° TTS audio integration
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 9:16 aspect ratio ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö TikTok
"""

import asyncio
import os
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime
import shutil

# Core imports
from sqlalchemy.orm import Session

# Video processing imports (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)
try:
    from moviepy.editor import (
        VideoFileClip, ImageSequenceClip, concatenate_videoclips,
        TextClip, CompositeVideoClip, ColorClip, ImageClip
    )
    from moviepy.video.fx import resize, fadein, fadeout
    MOVIEPY_AVAILABLE = True
    print("‚úÖ MoviePy available for video generation")
except ImportError:
    MOVIEPY_AVAILABLE = False
    print("‚ö†Ô∏è MoviePy not available - video generation will use simulation")

try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
    print("‚úÖ PIL available for image processing")
except ImportError:
    PIL_AVAILABLE = False
    print("‚ö†Ô∏è PIL not available - using basic image processing")

# Local imports
from app.core.config import get_settings
from app.models.product import Product
from app.models.script import Script

class AIVideoService:
    """AI Video Generation Service - Step 1 Implementation"""
    
    def __init__(self):
        self.settings = get_settings()
        
        # Video configuration
        self.video_config = {
            "width": 1080,           # TikTok 9:16 width
            "height": 1920,          # TikTok 9:16 height
            "fps": 30,               # Frame rate
            "duration_per_slide": 3, # Seconds per text slide
            "transition_duration": 0.5, # Fade transition time
            "background_color": "#000000", # Black background
            "text_color": "#FFFFFF",       # White text
            "accent_color": "#FF6B6B"      # Red accent
        }
        
        # Directories
        self.video_dir = Path("frontend/uploads/videos")
        self.audio_dir = Path("frontend/static/audio")
        self.template_dir = Path("frontend/video_templates")
        self.temp_dir = Path("temp/video_generation")
        
        # Create directories
        for directory in [self.video_dir, self.template_dir, self.temp_dir]:
            directory.mkdir(parents=True, exist_ok=True)
        
        print(f"üé¨ AI Video Service initialized")
        print(f"   üìÅ Video output: {self.video_dir}")
        print(f"   üéµ Audio source: {self.audio_dir}")
        print(f"   üé® Templates: {self.template_dir}")
        print(f"   üíæ Temp files: {self.temp_dir}")
        print(f"   üìê Format: {self.video_config['width']}x{self.video_config['height']} (9:16)")
    
    async def generate_product_video(
        self,
        product_id: int,
        script: Dict[str, Any],
        db: Session,
        video_style: str = "slideshow",
        include_audio: bool = True
    ) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏à‡∏≤‡∏Å AI script
        
        Args:
            product_id: ID ‡∏Ç‡∏≠‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
            script: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏≤‡∏Å AI
            db: Database session
            video_style: ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (slideshow, animated_text, product_showcase)
            include_audio: ‡∏£‡∏ß‡∏° TTS audio ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            
        Returns:
            Dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ video path ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        """
        
        try:
            print(f"üé¨ Starting video generation for product {product_id}")
            print(f"   üìù Script title: {script.get('title', 'Unknown')}")
            print(f"   üé® Style: {video_style}")
            print(f"   üîä Include audio: {include_audio}")
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
            product = db.query(Product).filter(Product.id == product_id).first()
            if not product:
                raise ValueError(f"Product {product_id} not found")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á unique video ID
            video_id = f"product_{product_id}_{int(time.time() * 1000)}"
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
            video_data = {
                "video_id": video_id,
                "product": product,
                "script": script,
                "style": video_style,
                "include_audio": include_audio
            }
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡∏≤‡∏° style ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
            if video_style == "slideshow":
                result = await self._generate_slideshow_video(video_data)
            elif video_style == "animated_text":
                result = await self._generate_animated_text_video(video_data)
            elif video_style == "product_showcase":
                result = await self._generate_product_showcase_video(video_data)
            else:
                # Default to slideshow
                result = await self._generate_slideshow_video(video_data)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° audio ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            if include_audio and result.get("success"):
                audio_result = await self._add_audio_to_video(result, script, video_id)
                if audio_result.get("success"):
                    result.update(audio_result)
            
            print(f"‚úÖ Video generation completed: {result.get('video_path', 'Unknown')}")
            return result
            
        except Exception as e:
            print(f"‚ùå Video generation failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "video_id": video_id if 'video_id' in locals() else None
            }
    
    async def _generate_slideshow_video(self, video_data: Dict[str, Any]) -> Dict[str, Any]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏ö‡∏ö slideshow ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå"""
        
        try:
            print("üéûÔ∏è Generating slideshow video...")
            
            if not MOVIEPY_AVAILABLE:
                return await self._simulate_video_generation(video_data, "slideshow")
            
            video_id = video_data["video_id"]
            product = video_data["product"]
            script = video_data["script"]
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡πÑ‡∏•‡∏î‡πå‡∏ï‡πà‡∏≤‡∏á ‡πÜ
            slides = []
            
            # Slide 1: Title slide
            title_slide = await self._create_title_slide(
                product.name,
                f"‡∏£‡∏≤‡∏Ñ‡∏≤ ‡∏ø{product.price:,.0f}",
                duration=4
            )
            slides.append(title_slide)
            
            # Slide 2: Product description
            description_slide = await self._create_text_slide(
                "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤",
                product.description or "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏û‡∏¥‡πÄ‡∏®‡∏©",
                duration=5
            )
            slides.append(description_slide)
            
            # Slide 3: Key features
            if product.key_features:
                features_text = "\n".join([f"‚úì {feature}" for feature in product.key_features[:4]])
            else:
                features_text = "‚úì ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ\n‚úì ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î\n‚úì ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢\n‚úì ‡∏™‡πà‡∏á‡∏ü‡∏£‡∏µ"
                
            features_slide = await self._create_text_slide(
                "‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏î‡πà‡∏ô",
                features_text,
                duration=5
            )
            slides.append(features_slide)
            
            # Slide 4: Call to action
            cta_slide = await self._create_cta_slide(
                script.get("call_to_action", "‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!"),
                f"‡∏£‡∏≤‡∏Ñ‡∏≤‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡∏ø{product.price:,.0f}",
                duration=4
            )
            slides.append(cta_slide)
            
            # ‡∏£‡∏ß‡∏°‡∏™‡πÑ‡∏•‡∏î‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
            video_path = await self._combine_slides_to_video(slides, video_id)
            
            return {
                "success": True,
                "video_path": str(video_path),
                "video_id": video_id,
                "duration": len(slides) * self.video_config["duration_per_slide"],
                "format": "mp4",
                "resolution": f"{self.video_config['width']}x{self.video_config['height']}",
                "style": "slideshow",
                "slides_count": len(slides)
            }
            
        except Exception as e:
            print(f"‚ùå Slideshow generation failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    async def _generate_animated_text_video(self, video_data: Dict[str, Any]) -> Dict[str, Any]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏ö‡∏ö animated text"""
        
        try:
            print("üìù Generating animated text video...")
            
            if not MOVIEPY_AVAILABLE:
                return await self._simulate_video_generation(video_data, "animated_text")
            
            video_id = video_data["video_id"]
            product = video_data["product"]
            script = video_data["script"]
            
            # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô ‡πÜ
            content = script.get("content", product.description or "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏î‡∏µ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤")
            text_segments = self._split_text_to_segments(content)
            
            clips = []
            current_time = 0
            
            for i, segment in enumerate(text_segments):
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á animated text clip
                text_clip = await self._create_animated_text_clip(
                    segment,
                    start_time=current_time,
                    duration=3,
                    animation_style="fade_in"
                )
                clips.append(text_clip)
                current_time += 3
            
            # Background
            background = ColorClip(
                size=(self.video_config["width"], self.video_config["height"]),
                color=self.video_config["background_color"],
                duration=current_time
            )
            
            # ‡∏£‡∏ß‡∏° clips
            final_video = CompositeVideoClip([background] + clips)
            
            # Export video
            video_path = self.video_dir / f"{video_id}_animated.mp4"
            final_video.write_videofile(
                str(video_path),
                fps=self.video_config["fps"],
                audio=False,
                verbose=False,
                logger=None
            )
            
            return {
                "success": True,
                "video_path": str(video_path),
                "video_id": video_id,
                "duration": current_time,
                "format": "mp4",
                "resolution": f"{self.video_config['width']}x{self.video_config['height']}",
                "style": "animated_text",
                "segments_count": len(text_segments)
            }
            
        except Exception as e:
            print(f"‚ùå Animated text generation failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    async def _generate_product_showcase_video(self, video_data: Dict[str, Any]) -> Dict[str, Any]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏ö‡∏ö product showcase"""
        
        try:
            print("üõçÔ∏è Generating product showcase video...")
            
            if not MOVIEPY_AVAILABLE:
                return await self._simulate_video_generation(video_data, "product_showcase")
            
            video_id = video_data["video_id"]
            product = video_data["product"]
            
            clips = []
            
            # Opening sequence
            opening = await self._create_opening_sequence(product.name, duration=3)
            clips.append(opening)
            
            # Product images (if available)
            if product.images:
                for i, image_path in enumerate(product.images[:3]):  # Max 3 images
                    image_clip = await self._create_image_showcase_clip(
                        image_path,
                        duration=4,
                        zoom_effect=True
                    )
                    clips.append(image_clip)
            
            # Features highlight
            features_clip = await self._create_features_highlight(
                product.key_features or ["‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ", "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î", "‡∏™‡πà‡∏á‡∏ü‡∏£‡∏µ"],
                duration=6
            )
            clips.append(features_clip)
            
            # Price highlight
            price_clip = await self._create_price_highlight(
                product.price,
                getattr(product, 'original_price', None),
                duration=4
            )
            clips.append(price_clip)
            
            # ‡∏£‡∏ß‡∏° clips
            final_video = concatenate_videoclips(clips, method="compose")
            
            # Export
            video_path = self.video_dir / f"{video_id}_showcase.mp4"
            final_video.write_videofile(
                str(video_path),
                fps=self.video_config["fps"],
                audio=False,
                verbose=False,
                logger=None
            )
            
            return {
                "success": True,
                "video_path": str(video_path),
                "video_id": video_id,
                "duration": final_video.duration,
                "format": "mp4",
                "resolution": f"{self.video_config['width']}x{self.video_config['height']}",
                "style": "product_showcase",
                "clips_count": len(clips)
            }
            
        except Exception as e:
            print(f"‚ùå Product showcase generation failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    async def _add_audio_to_video(
        self,
        video_result: Dict[str, Any],
        script: Dict[str, Any],
        video_id: str
    ) -> Dict[str, Any]:
        """‡πÄ‡∏û‡∏¥‡πà‡∏° TTS audio ‡∏•‡∏á‡πÉ‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠"""
        
        try:
            print("üîä Adding TTS audio to video...")
            
            if not video_result.get("success"):
                return {"success": False, "error": "Video generation failed"}
            
            # Import TTS service
            try:
                from app.services.tts.enhanced_tts_service import enhanced_tts_service
            except ImportError:
                print("‚ö†Ô∏è TTS service not available - video without audio")
                return video_result
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á TTS audio
            script_content = script.get("content", "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏î‡∏µ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤")
            audio_result = await enhanced_tts_service.generate_script_audio(
                script_id=f"video_{video_id}",
                content=script_content,
                language="th"
            )
            
            if not audio_result[0]:  # audio_path is first element
                print("‚ö†Ô∏è TTS generation failed - keeping video without audio")
                return video_result
            
            audio_path = audio_result[0]
            video_path = video_result["video_path"]
            
            # Combine video + audio
            if MOVIEPY_AVAILABLE:
                video_with_audio_path = await self._combine_video_audio(
                    video_path,
                    audio_path,
                    video_id
                )
                
                return {
                    **video_result,
                    "video_path": video_with_audio_path,
                    "has_audio": True,
                    "audio_path": audio_path,
                    "tts_generated": True
                }
            else:
                # Simulation mode
                return {
                    **video_result,
                    "has_audio": True,
                    "audio_path": audio_path,
                    "tts_generated": True,
                    "note": "Audio generated but not combined (MoviePy not available)"
                }
                
        except Exception as e:
            print(f"‚ùå Audio addition failed: {str(e)}")
            return {
                **video_result,
                "audio_error": str(e),
                "has_audio": False
            }
    
    async def _combine_video_audio(
        self,
        video_path: str,
        audio_path: str,
        video_id: str
    ) -> str:
        """‡∏£‡∏ß‡∏° video ‡πÅ‡∏•‡∏∞ audio ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô"""
        
        try:
            if not MOVIEPY_AVAILABLE:
                return video_path
            
            video_clip = VideoFileClip(video_path)
            audio_clip = VideoFileClip(audio_path).audio if os.path.exists(audio_path) else None
            
            if audio_clip:
                # Adjust audio duration to match video
                if audio_clip.duration > video_clip.duration:
                    audio_clip = audio_clip.subclip(0, video_clip.duration)
                elif audio_clip.duration < video_clip.duration:
                    # Loop audio if shorter than video
                    loops_needed = int(video_clip.duration / audio_clip.duration) + 1
                    audio_clip = concatenate_audioclips([audio_clip] * loops_needed).subclip(0, video_clip.duration)
                
                final_video = video_clip.set_audio(audio_clip)
            else:
                final_video = video_clip
            
            # Export with audio
            output_path = self.video_dir / f"{video_id}_with_audio.mp4"
            final_video.write_videofile(
                str(output_path),
                fps=self.video_config["fps"],
                verbose=False,
                logger=None
            )
            
            # Cleanup
            video_clip.close()
            if audio_clip:
                audio_clip.close()
            final_video.close()
            
            return str(output_path)
            
        except Exception as e:
            print(f"‚ùå Video-audio combination failed: {str(e)}")
            return video_path
    
    async def _simulate_video_generation(
        self,
        video_data: Dict[str, Any],
        style: str
    ) -> Dict[str, Any]:
        """‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠ MoviePy ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"""
        
        print(f"üé≠ Simulating {style} video generation...")
        
        video_id = video_data["video_id"]
        product = video_data["product"]
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå placeholder
        placeholder_path = self.video_dir / f"{video_id}_simulated.txt"
        
        simulation_data = {
            "video_id": video_id,
            "product_id": product.id,
            "product_name": product.name,
            "style": style,
            "generated_at": datetime.utcnow().isoformat(),
            "simulation": True,
            "note": "This is a simulated video generation. Install MoviePy for actual video creation."
        }
        
        with open(placeholder_path, 'w', encoding='utf-8') as f:
            json.dump(simulation_data, f, indent=2, ensure_ascii=False)
        
        return {
            "success": True,
            "video_path": str(placeholder_path),
            "video_id": video_id,
            "duration": 20,  # Estimated duration
            "format": "simulation",
            "resolution": f"{self.video_config['width']}x{self.video_config['height']}",
            "style": style,
            "simulation": True,
            "note": "MoviePy not available - simulation mode"
        }
    
    # Helper methods for video creation
    async def _create_title_slide(self, title: str, subtitle: str, duration: int):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡πÑ‡∏•‡∏î‡πå title"""
        if not MOVIEPY_AVAILABLE:
            return None
            
        # Background
        bg = ColorClip(
            size=(self.video_config["width"], self.video_config["height"]),
            color=self.video_config["background_color"],
            duration=duration
        )
        
        # Title text
        title_clip = TextClip(
            title,
            fontsize=80,
            color=self.video_config["text_color"],
            font='Arial-Bold'
        ).set_position('center').set_duration(duration)
        
        # Subtitle text
        subtitle_clip = TextClip(
            subtitle,
            fontsize=50,
            color=self.video_config["accent_color"],
            font='Arial'
        ).set_position(('center', 'center+100')).set_duration(duration)
        
        return CompositeVideoClip([bg, title_clip, subtitle_clip])
    
    async def _create_text_slide(self, header: str, content: str, duration: int):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡πÑ‡∏•‡∏î‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        if not MOVIEPY_AVAILABLE:
            return None
            
        bg = ColorClip(
            size=(self.video_config["width"], self.video_config["height"]),
            color=self.video_config["background_color"],
            duration=duration
        )
        
        header_clip = TextClip(
            header,
            fontsize=60,
            color=self.video_config["accent_color"],
            font='Arial-Bold'
        ).set_position(('center', 300)).set_duration(duration)
        
        content_clip = TextClip(
            content,
            fontsize=45,
            color=self.video_config["text_color"],
            font='Arial',
            size=(900, None),
            method='caption'
        ).set_position('center').set_duration(duration)
        
        return CompositeVideoClip([bg, header_clip, content_clip])
    
    async def _create_cta_slide(self, cta_text: str, price_text: str, duration: int):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡πÑ‡∏•‡∏î‡πå Call to Action"""
        if not MOVIEPY_AVAILABLE:
            return None
            
        bg = ColorClip(
            size=(self.video_config["width"], self.video_config["height"]),
            color=self.video_config["accent_color"],
            duration=duration
        )
        
        cta_clip = TextClip(
            cta_text,
            fontsize=70,
            color="white",
            font='Arial-Bold'
        ).set_position('center').set_duration(duration)
        
        price_clip = TextClip(
            price_text,
            fontsize=80,
            color="yellow",
            font='Arial-Bold'
        ).set_position(('center', 'center+150')).set_duration(duration)
        
        return CompositeVideoClip([bg, cta_clip, price_clip])
    
    async def _combine_slides_to_video(self, slides: List, video_id: str) -> Path:
        """‡∏£‡∏ß‡∏°‡∏™‡πÑ‡∏•‡∏î‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠"""
        if not MOVIEPY_AVAILABLE or not slides:
            # Create placeholder file
            placeholder_path = self.video_dir / f"{video_id}_placeholder.mp4"
            placeholder_path.touch()
            return placeholder_path
        
        # Add transitions
        clips_with_transitions = []
        for i, slide in enumerate(slides):
            if slide is None:
                continue
                
            if i > 0:
                slide = slide.crossfadein(self.video_config["transition_duration"])
            clips_with_transitions.append(slide)
        
        if not clips_with_transitions:
            placeholder_path = self.video_dir / f"{video_id}_empty.mp4"
            placeholder_path.touch()
            return placeholder_path
        
        # Concatenate
        final_video = concatenate_videoclips(clips_with_transitions, method="compose")
        
        # Export
        output_path = self.video_dir / f"{video_id}.mp4"
        final_video.write_videofile(
            str(output_path),
            fps=self.video_config["fps"],
            audio=False,
            verbose=False,
            logger=None
        )
        
        # Cleanup
        final_video.close()
        for clip in clips_with_transitions:
            clip.close()
        
        return output_path
    
    def _split_text_to_segments(self, text: str, max_length: int = 100) -> List[str]:
        """‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô ‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö animation"""
        
        sentences = text.split('.')
        segments = []
        current_segment = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            if len(current_segment + sentence) <= max_length:
                current_segment += sentence + ". "
            else:
                if current_segment:
                    segments.append(current_segment.strip())
                current_segment = sentence + ". "
        
        if current_segment:
            segments.append(current_segment.strip())
        
        return segments or [text]
    
    async def get_video_status(self, video_id: str) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠"""
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        possible_files = list(self.video_dir.glob(f"{video_id}*"))
        
        if not possible_files:
            return {
                "video_id": video_id,
                "exists": False,
                "status": "not_found"
            }
        
        video_file = possible_files[0]
        file_size = video_file.stat().st_size if video_file.exists() else 0
        
        return {
            "video_id": video_id,
            "exists": True,
            "status": "completed",
            "file_path": str(video_file),
            "file_size_mb": round(file_size / (1024 * 1024), 2),
            "created_at": datetime.fromtimestamp(video_file.stat().st_ctime).isoformat(),
            "is_simulation": video_file.suffix == ".txt"
        }
    
    def get_service_status(self) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á service"""
        
        return {
            "service_name": "AI Video Service",
            "version": "1.0.0",
            "status": "active",
            "capabilities": {
                "moviepy_available": MOVIEPY_AVAILABLE,
                "pil_available": PIL_AVAILABLE,
                "video_generation": MOVIEPY_AVAILABLE,
                "simulation_mode": not MOVIEPY_AVAILABLE
            },
            "video_config": self.video_config,
            "directories": {
                "video_output": str(self.video_dir),
                "audio_source": str(self.audio_dir),
                "templates": str(self.template_dir),
                "temp": str(self.temp_dir)
            },
            "supported_styles": [
                "slideshow",
                "animated_text", 
                "product_showcase"
            ],
            "dependencies_status": {
                "moviepy": "‚úÖ Available" if MOVIEPY_AVAILABLE else "‚ùå Not installed",
                "pil": "‚úÖ Available" if PIL_AVAILABLE else "‚ùå Not installed"
            }
        }

# Global service instance
ai_video_service = AIVideoService()

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠ import
print("üé¨ AI Video Service loaded")
status = ai_video_service.get_service_status()
if not MOVIEPY_AVAILABLE:
    print("üì¶ To enable video generation, install dependencies:")
    print("   pip install moviepy pillow")
print(f"üéØ Service ready in {'production' if MOVIEPY_AVAILABLE else 'simulation'} mode")