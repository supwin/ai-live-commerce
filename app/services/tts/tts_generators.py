# app/services/tts/tts_generators.py
"""TTS Generator Classes for Different Providers"""

import hashlib
import time
import tempfile
from pathlib import Path
from typing import Dict, Tuple, Optional

from .tts_config import (
    EDGE_TTS_AVAILABLE, ELEVENLABS_AVAILABLE, AZURE_AVAILABLE, GTTS_AVAILABLE,
    TTSConfig
)
from .voice_providers import VoiceProviders
from .audio_processor import AudioProcessor

if EDGE_TTS_AVAILABLE:
    import edge_tts

if ELEVENLABS_AVAILABLE:
    from elevenlabs import generate

if AZURE_AVAILABLE:
    import azure.cognitiveservices.speech as speechsdk

if GTTS_AVAILABLE:
    from gtts import gTTS

class EdgeTTSGenerator:
    """Edge TTS Generator"""
    
    @staticmethod
    async def generate(
        text: str, 
        script_id: str, 
        voice_config: Dict, 
        emotion: str, 
        intensity: float,
        script_title: str,
        audio_dir: Path
    ) -> Tuple[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Edge TTS ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ LAME Padding ‡πÅ‡∏•‡∏∞ Filename Collision"""
        
        try:
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å voice_config ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ default
            voice_name = voice_config.get("voice", "th-TH-PremwadeeNeural")
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            cleaned_text = AudioProcessor.clean_text_for_tts(text)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á unique filename ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° timestamp ‡πÅ‡∏•‡∏∞ text hash
            timestamp = str(int(time.time() * 1000))  # milliseconds
            text_hash = hashlib.md5(cleaned_text.encode()).hexdigest()[:8]
            filename = f"script_{script_id}_{text_hash}_{timestamp}.mp3"
            
            file_path = audio_dir / filename
            web_url = f"/static/audio/{filename}"
            
            print(f"   üìù Using plain text (no SSML) to prevent concatenation")
            print(f"   üßπ Text: '{cleaned_text}'")
            print(f"   üìÅ Unique filename: {filename}")
            
            # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏´‡∏≤‡∏Å‡∏°‡∏µ (‡πÉ‡∏ä‡πâ pattern ‡πÄ‡∏î‡∏¥‡∏°)
            old_pattern = f"script_{script_id}_{text_hash}_*.mp3"
            import glob
            for old_file in glob.glob(str(audio_dir / old_pattern)):
                try:
                    Path(old_file).unlink()
                    print(f"   üóëÔ∏è Removed old file: {Path(old_file).name}")
                except:
                    pass
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á TTS ‡∏î‡πâ‡∏ß‡∏¢ Edge TTS ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ SSML
            communicate = edge_tts.Communicate(cleaned_text, voice_name)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏Å‡πà‡∏≠‡∏ô
            temp_path = file_path.with_suffix('.tmp.mp3')
            await communicate.save(str(temp_path))
            
            print(f"   üéµ Edge TTS raw file generated: {temp_path.name}")
            
            # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ LAME Padding ‡πÅ‡∏•‡∏∞ Contamination
            if await AudioProcessor.fix_lame_padding_and_contamination(temp_path, file_path, script_title, emotion):
                print(f"   ‚úÖ Edge TTS generation completed (LAME padding fixed)")
                return str(file_path), web_url
            else:
                print(f"   ‚ùå LAME padding fix failed")
                raise Exception("LAME padding fix failed")
                
        except Exception as e:
            print(f"   ‚ùå Edge TTS failed: {e}")
            raise

class ElevenLabsGenerator:
    """ElevenLabs TTS Generator"""
    
    @staticmethod
    async def generate(
        text: str, 
        script_id: str, 
        voice_config: Dict, 
        emotion: str, 
        intensity: float,
        script_title: str,
        audio_dir: Path
    ) -> Tuple[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ ElevenLabs AI"""
        
        try:
            voice_id = voice_config.get("voice_id", "pNInz6obpgDQGcFmaJgB")
            
            # ‡∏õ‡∏£‡∏±‡∏ö text ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
            emotional_prefixes = VoiceProviders.get_emotional_prefixes()
            prefix = emotional_prefixes.get(emotion, "")
            emotional_text = f"{prefix}{text}" if prefix else text
            
            filename = f"script_{script_id}_{hashlib.md5(text.encode()).hexdigest()[:8]}.mp3"
            file_path = audio_dir / filename
            web_url = f"/static/audio/{filename}"
            
            print(f"   ü§ñ Using ElevenLabs voice: {voice_id}")
            print(f"   üìÅ Output: {file_path}")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á audio
            audio = generate(
                text=emotional_text,
                voice=voice_id,
                model="eleven_multilingual_v2"
            )
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
            with open(file_path, "wb") as f:
                f.write(audio)
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata
            await AudioProcessor.enhance_audio_quality(file_path, script_title, emotion)
            
            print(f"   ‚úÖ ElevenLabs generation completed")
            return str(file_path), web_url
            
        except Exception as e:
            print(f"   ‚ùå ElevenLabs failed: {e}")
            raise

class AzureGenerator:
    """Azure Cognitive Services TTS Generator"""
    
    @staticmethod
    async def generate(
        text: str, 
        script_id: str, 
        voice_config: Dict, 
        emotion: str, 
        intensity: float,
        script_title: str,
        audio_dir: Path,
        config: TTSConfig
    ) -> Tuple[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Azure Cognitive Services"""
        
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á Azure Speech config
            speech_config = speechsdk.SpeechConfig(
                subscription=config.azure_speech_key, 
                region=config.azure_speech_region
            )
            
            voice_name = voice_config.get("voice", "th-TH-PremwadeeNeural")
            speech_config.speech_synthesis_voice_name = voice_name
            
            filename = f"script_{script_id}_{hashlib.md5(text.encode()).hexdigest()[:8]}.wav"
            file_path = audio_dir / filename
            web_url = f"/static/audio/{filename}"
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á SSML ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
            ssml_text = AzureGenerator._create_emotional_ssml(text, voice_name, emotion, intensity)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á synthesizer
            audio_config = speechsdk.audio.AudioOutputConfig(filename=str(file_path))
            synthesizer = speechsdk.SpeechSynthesizer(
                speech_config=speech_config, 
                audio_config=audio_config
            )
            
            # ‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            result = synthesizer.speak_ssml_async(ssml_text).get()
            
            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô MP3 ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata
                mp3_path = await AudioProcessor.convert_to_mp3(file_path, script_title, emotion)
                print(f"   ‚úÖ Azure Speech generation completed")
                return str(mp3_path), web_url.replace('.wav', '.mp3')
            else:
                raise Exception(f"Azure synthesis failed: {result.reason}")
                
        except Exception as e:
            print(f"   ‚ùå Azure Speech failed: {e}")
            raise
    
    @staticmethod
    def _create_emotional_ssml(text: str, voice_name: str, emotion: str, intensity: float) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á SSML ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö SSML
        emotion_mapping = VoiceProviders.get_emotion_mapping()
        ssml_emotion = emotion_mapping.get(emotion, emotion)
        
        # ‡∏õ‡∏£‡∏±‡∏ö intensity
        intensity_level = "strong" if intensity > 1.5 else "moderate" if intensity > 1.0 else "mild"
        
        # ‡∏î‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ prosody
        prosody_settings = VoiceProviders.get_prosody_settings(emotion)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á SSML
        ssml = f"""
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="th-TH">
            <voice name="{voice_name}">
                <mstts:express-as style="{ssml_emotion}" styledegree="{intensity}">
                    <prosody rate="{prosody_settings['rate']}" pitch="{prosody_settings['pitch']}">
                        {text}
                    </prosody>
                </mstts:express-as>
            </voice>
        </speak>
        """
        
        return ssml.strip()

class BasicTTSGenerator:
    """Basic gTTS Fallback Generator"""
    
    @staticmethod
    async def generate(
        text: str, 
        script_id: str, 
        language: str,
        script_title: str,
        audio_dir: Path
    ) -> Tuple[str, str]:
        """Fallback ‡πÄ‡∏õ‡πá‡∏ô basic gTTS ‡∏û‡∏£‡πâ‡∏≠‡∏° unique filename"""
        try:
            if not GTTS_AVAILABLE:
                print("   ‚ùå gTTS not available for fallback")
                return "", ""
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            cleaned_text = AudioProcessor.clean_text_for_tts(text)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á unique filename
            timestamp = str(int(time.time() * 1000))
            text_hash = hashlib.md5(cleaned_text.encode()).hexdigest()[:8]
            filename = f"script_{script_id}_{text_hash}_{timestamp}.mp3"
            
            file_path = audio_dir / filename
            web_url = f"/static/audio/{filename}"
            
            print(f"   üì¢ Using basic gTTS")
            print(f"   üìÅ Unique filename: {filename}")
            print(f"   üßπ Text: '{cleaned_text[:30]}...'")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢ gTTS
            tts = gTTS(text=cleaned_text, lang=language, slow=False)
            tts.save(str(file_path))
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
            try:
                AudioProcessor.clean_metadata(file_path, script_title or "Basic TTS Audio", "neutral")
            except:
                pass
            
            print(f"   ‚úÖ Basic gTTS generation completed")
            return str(file_path), web_url
            
        except Exception as e:
            print(f"   ‚ùå Basic TTS failed: {e}")
            return "", ""