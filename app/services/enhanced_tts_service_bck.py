# ‡πÉ‡∏ô app/services/enhanced_tts_service.py - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡πà‡∏ß‡∏ô metadata contamination

import os
import asyncio
import aiofiles
import tempfile
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
import hashlib
import json
from datetime import datetime

# Safe TTS Providers Import
EDGE_TTS_AVAILABLE = False
ELEVENLABS_AVAILABLE = False
AZURE_AVAILABLE = False
AUDIO_PROCESSING_AVAILABLE = False

# Edge TTS
try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
    print("‚úÖ Edge TTS library loaded")
except ImportError as e:
    print(f"‚ö†Ô∏è Edge TTS not available: {e}")

# ElevenLabs
try:
    from elevenlabs import generate, set_api_key, voices
    ELEVENLABS_AVAILABLE = True
    print("‚úÖ ElevenLabs library loaded")
except ImportError as e:
    print(f"‚ö†Ô∏è ElevenLabs not available: {e}")

# Azure Speech
try:
    import azure.cognitiveservices.speech as speechsdk
    AZURE_AVAILABLE = True
    print("‚úÖ Azure Speech library loaded")
except ImportError as e:
    print(f"‚ö†Ô∏è Azure Speech not available: {e}")

# Audio processing - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£ import
try:
    from pydub import AudioSegment
    from pydub.effects import normalize, compress_dynamic_range
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° mutagen ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ metadata
    from mutagen.mp3 import MP3
    from mutagen.id3 import ID3, TIT2, TPE1, TALB, TDRC, TCON
    AUDIO_PROCESSING_AVAILABLE = True
    print("‚úÖ Audio processing libraries loaded")
except ImportError as e:
    print(f"‚ö†Ô∏è Audio processing not available: {e}")
    AUDIO_PROCESSING_AVAILABLE = False

# Basic gTTS fallback
try:
    from gtts import gTTS
    GTTS_AVAILABLE = True
    print("‚úÖ Basic gTTS loaded as fallback")
except ImportError as e:
    print(f"‚ùå gTTS not available: {e}")
    GTTS_AVAILABLE = False

class EnhancedTTSService:
    """Enhanced TTS Service with multiple providers and emotional support"""
    
    def __init__(self):
        self.audio_dir = Path("frontend/static/audio")
        self.audio_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize API keys
        self.elevenlabs_api_key = None
        self.azure_speech_key = None
        self.azure_speech_region = "southeastasia"
        
        # Provider configurations
        self.providers = {
            "edge": {
                "available": EDGE_TTS_AVAILABLE,
                "voices": {},
                "supports_emotions": True,
                "quality": "high",
                "cost": "free"
            },
            "elevenlabs": {
                "available": ELEVENLABS_AVAILABLE,
                "voices": {},
                "supports_emotions": True,
                "quality": "premium",
                "cost": "paid"
            },
            "azure": {
                "available": AZURE_AVAILABLE,
                "voices": {},
                "supports_emotions": True,
                "quality": "enterprise",
                "cost": "paid"
            }
        }
        
        # Load API keys and initialize providers
        self._load_api_keys()
        self._initialize_providers()
        
        print(f"üéµ Enhanced TTS Service initialized")
        available_providers = [p for p, config in self.providers.items() if config['available']]
        print(f"   üìä Available providers: {available_providers}")

    def _load_api_keys(self):
        """‡πÇ‡∏´‡∏•‡∏î API keys ‡∏à‡∏≤‡∏Å environment variables"""
        try:
            self.elevenlabs_api_key = os.getenv("ELEVENLABS_API_KEY")
            self.azure_speech_key = os.getenv("AZURE_SPEECH_KEY") 
            self.azure_speech_region = os.getenv("AZURE_SPEECH_REGION", "southeastasia")
            
            # Configure ElevenLabs if available
            if self.elevenlabs_api_key and ELEVENLABS_AVAILABLE:
                try:
                    set_api_key(self.elevenlabs_api_key)
                    print("‚úÖ ElevenLabs API key configured")
                    self.providers["elevenlabs"]["available"] = True
                except Exception as e:
                    print(f"‚ö†Ô∏è ElevenLabs configuration failed: {e}")
                    self.providers["elevenlabs"]["available"] = False
            else:
                if not self.elevenlabs_api_key:
                    print("‚ÑπÔ∏è ElevenLabs API key not found (optional)")
                self.providers["elevenlabs"]["available"] = False
            
            # Configure Azure if available
            if self.azure_speech_key and AZURE_AVAILABLE:
                print("‚úÖ Azure Speech API key configured")
                self.providers["azure"]["available"] = True
            else:
                if not self.azure_speech_key:
                    print("‚ÑπÔ∏è Azure Speech API key not found (optional)")
                self.providers["azure"]["available"] = False
                
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading API keys: {e}")
            self.elevenlabs_api_key = None
            self.azure_speech_key = None
            self.providers["elevenlabs"]["available"] = False
            self.providers["azure"]["available"] = False

    def _initialize_providers(self):
        """Initialize voice configurations for each provider"""
        try:
            if self.providers["edge"]["available"]:
                self.providers["edge"]["voices"] = self._get_edge_voices()
            
            if self.providers["elevenlabs"]["available"]:
                self.providers["elevenlabs"]["voices"] = self._get_elevenlabs_voices()
            else:
                self.providers["elevenlabs"]["voices"] = {}
            
            if self.providers["azure"]["available"]:
                self.providers["azure"]["voices"] = self._get_azure_voices()
            else:
                self.providers["azure"]["voices"] = {}
                
            print(f"   üìä Edge TTS voices: {len(self.providers['edge']['voices'])}")
            print(f"   ü§ñ ElevenLabs voices: {len(self.providers['elevenlabs']['voices'])}")
            print(f"   üè¢ Azure voices: {len(self.providers['azure']['voices'])}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error initializing providers: {e}")
            for provider in self.providers:
                if "voices" not in self.providers[provider]:
                    self.providers[provider]["voices"] = {}
    
    def _get_edge_voices(self) -> Dict[str, Any]:
        """‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Edge TTS voices ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        return {
            "th_female_professional": {
                "voice": "th-TH-PremwadeeNeural",
                "name": "Premwadee (Thai Female Professional)",
                "language": "th-TH",
                "gender": "female",
                "emotions": ["cheerful", "sad", "angry", "fearful", "disgruntled", "serious", "affectionate", "gentle", "envious"]
            },
            "th_male_casual": {
                "voice": "th-TH-NiwatNeural", 
                "name": "Niwat (Thai Male Casual)",
                "language": "th-TH",
                "gender": "male",
                "emotions": ["cheerful", "sad", "angry", "fearful", "disgruntled", "serious"]
            },
            "th_female_warm": {
                "voice": "th-TH-AcharaNeural",
                "name": "Achara (Thai Female Warm)",
                "language": "th-TH", 
                "gender": "female",
                "emotions": ["cheerful", "sad", "angry", "fearful", "disgruntled", "serious", "affectionate", "gentle"]
            },
            "en_female_professional": {
                "voice": "en-US-JennyNeural",
                "name": "Jenny (English Female Professional)",
                "language": "en-US",
                "gender": "female",
                "emotions": ["cheerful", "sad", "angry", "fearful", "disgruntled", "serious", "affectionate", "gentle", "envious"]
            }
        }
    
    def _get_elevenlabs_voices(self) -> Dict[str, Any]:
        """‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ElevenLabs voices"""
        try:
            if not hasattr(self, 'elevenlabs_api_key') or not self.elevenlabs_api_key:
                print("‚ÑπÔ∏è ElevenLabs API key not configured")
                return {}
            
            if not ELEVENLABS_AVAILABLE:
                print("‚ÑπÔ∏è ElevenLabs library not available")
                return {}
            
            return {
                "adam": {
                    "voice_id": "pNInz6obpgDQGcFmaJgB",
                    "name": "Adam (English Male)",
                    "language": "en",
                    "gender": "male",
                    "emotions": ["neutral", "excited", "sad", "angry", "cheerful", "serious"]
                },
                "bella": {
                    "voice_id": "EXAVITQu4vr4xnSDxMaL",
                    "name": "Bella (English Female)",
                    "language": "en", 
                    "gender": "female",
                    "emotions": ["neutral", "excited", "sad", "angry", "cheerful", "serious", "gentle"]
                },
                "rachel": {
                    "voice_id": "21m00Tcm4TlvDq8ikWAM",
                    "name": "Rachel (English Female Professional)",
                    "language": "en",
                    "gender": "female", 
                    "emotions": ["neutral", "professional", "confident", "cheerful", "serious"]
                }
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error getting ElevenLabs voices: {e}")
            return {}
    
    def _get_azure_voices(self) -> Dict[str, Any]:
        """‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Azure Speech voices"""
        try:
            if not hasattr(self, 'azure_speech_key') or not self.azure_speech_key:
                print("‚ÑπÔ∏è Azure Speech API key not configured")
                return {}
                
            if not AZURE_AVAILABLE:
                print("‚ÑπÔ∏è Azure Speech library not available")
                return {}
                
            return {
                "th_female_premium": {
                    "voice": "th-TH-PremwadeeNeural",
                    "name": "Premwadee Premium (Azure)",
                    "language": "th-TH",
                    "gender": "female", 
                    "emotions": ["cheerful", "sad", "angry", "fearful", "serious", "gentle"]
                },
                "th_male_premium": {
                    "voice": "th-TH-NiwatNeural",
                    "name": "Niwat Premium (Azure)",
                    "language": "th-TH",
                    "gender": "male",
                    "emotions": ["cheerful", "sad", "angry", "fearful", "serious"]
                }
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error getting Azure voices: {e}")
            return {}

    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ metadata ‡πÅ‡∏ö‡∏ö‡∏™‡∏∞‡∏≠‡∏≤‡∏î
    def _clean_metadata(self, file_path: Path, script_title: str = "", emotion: str = ""):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ metadata ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"""
        try:
            if not AUDIO_PROCESSING_AVAILABLE:
                print("   ‚ö†Ô∏è Audio processing not available for metadata cleaning")
                return
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå MP3
            audio_file = MP3(str(file_path))
            
            # ‡∏•‡∏ö metadata ‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            audio_file.delete()
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á ID3 tags ‡πÉ‡∏´‡∏°‡πà
            audio_file.add_tags()
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ metadata ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            audio_file.tags.add(TIT2(encoding=3, text=script_title or f"AI Live Commerce Script"))
            audio_file.tags.add(TPE1(encoding=3, text="AI Live Commerce TTS"))
            audio_file.tags.add(TALB(encoding=3, text="Product Scripts"))
            audio_file.tags.add(TDRC(encoding=3, text=str(datetime.now().year)))
            audio_file.tags.add(TCON(encoding=3, text=f"Speech/{emotion}"))
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata ‡πÉ‡∏´‡∏°‡πà
            audio_file.save()
            
            print(f"   üè∑Ô∏è Metadata cleaned and updated")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Metadata cleaning failed: {e}")
            # ‡πÑ‡∏°‡πà throw error ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
    
    async def _enhance_audio_quality(self, file_path: Path, script_title: str = "", emotion: str = ""):
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata"""
        try:
            if not AUDIO_PROCESSING_AVAILABLE:
                return
                
            print(f"   üéß Enhancing audio quality...")
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            audio = AudioSegment.from_file(file_path)
            
            # Normalize volume
            audio = normalize(audio)
            
            # Compress dynamic range ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
            audio = compress_dynamic_range(audio, threshold=-20.0, ratio=2.0, attack=5.0, release=50.0)
            
            # ‡∏õ‡∏£‡∏±‡∏ö sample rate ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏î‡∏µ
            audio = audio.set_frame_rate(22050)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            temp_path = file_path.with_suffix('.tmp.mp3')
            
            # Export ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
            audio.export(
                temp_path, 
                format="mp3", 
                bitrate="128k",
                parameters=["-q:a", "2", "-ar", "22050"]  # ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á
            )
            
            # ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏°‡∏≤‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
            if temp_path.exists():
                file_path.unlink()  # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
                temp_path.rename(file_path)  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata
            self._clean_metadata(file_path, script_title, emotion)
            
            print(f"   ‚úÖ Audio quality enhanced and metadata cleaned")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Audio enhancement failed: {e}")
            # ‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            try:
                self._clean_metadata(file_path, script_title, emotion)
            except:
                pass

    async def generate_emotional_speech(
        self,
        text: str,
        script_id: str,
        provider: str = "edge",
        voice_config: Optional[Dict] = None,
        emotion: str = "neutral",
        intensity: float = 1.0,
        language: str = "th",
        script_title: str = ""
    ) -> Tuple[str, str]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏û‡∏£‡πâ‡∏≠‡∏° unique filename
        """
        
        try:
            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö test endpoint ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ timestamp ‡πÄ‡∏õ‡πá‡∏ô script_id
            if script_id == "test" or script_id.startswith("test"):
                import time
                unique_id = f"test_{int(time.time() * 1000)}"
            else:
                unique_id = script_id
            
            print(f"üéµ Generating speech with provider: {provider}")
            print(f"   üìù Text: {text[:50]}...")
            print(f"   üé≠ Emotion: {emotion}")
            print(f"   üÜî Unique ID: {unique_id}")
            
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å provider ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏
            if provider == "basic" or provider == "gtts":
                return await self._generate_basic_speech(text, unique_id, language, script_title)
            elif provider == "edge":
                return await self._generate_edge_speech(text, unique_id, voice_config or {}, emotion, intensity, script_title)
            elif provider == "elevenlabs":
                return await self._generate_elevenlabs_speech(text, unique_id, voice_config or {}, emotion, intensity, script_title)
            elif provider == "azure":
                return await self._generate_azure_speech(text, unique_id, voice_config or {}, emotion, intensity, script_title)
            else:
                print(f"   ‚ö†Ô∏è Unknown provider '{provider}', falling back to basic")
                return await self._generate_basic_speech(text, unique_id, language, script_title)
                
        except Exception as e:
            print(f"‚ùå Error generating speech with {provider}: {e}")
            # Fallback to basic TTS
            try:
                print(f"   üîÑ Falling back to basic TTS")
                return await self._generate_basic_speech(text, unique_id, language, script_title)
            except Exception as fallback_error:
                print(f"‚ùå Even basic TTS failed: {fallback_error}")
                return "", ""
    
    async def _generate_edge_speech(
        self, 
        text: str, 
        script_id: str, 
        voice_config: Dict, 
        emotion: str, 
        intensity: float,
        script_title: str = ""
    ) -> Tuple[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Edge TTS ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ LAME Padding ‡πÅ‡∏•‡∏∞ Filename Collision"""
        
        try:
            import time
            
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å voice_config ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ default
            voice_name = voice_config.get("voice", "th-TH-PremwadeeNeural")
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            cleaned_text = self._clean_text_for_tts(text)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á unique filename ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° timestamp ‡πÅ‡∏•‡∏∞ text hash
            timestamp = str(int(time.time() * 1000))  # milliseconds
            text_hash = hashlib.md5(cleaned_text.encode()).hexdigest()[:8]
            filename = f"script_{script_id}_{text_hash}_{timestamp}.mp3"
            
            file_path = self.audio_dir / filename
            web_url = f"/static/audio/{filename}"
            
            print(f"   üìù Using plain text (no SSML) to prevent concatenation")
            print(f"   üßπ Text: '{cleaned_text}'")
            print(f"   üìÅ Unique filename: {filename}")
            
            # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏´‡∏≤‡∏Å‡∏°‡∏µ (‡πÉ‡∏ä‡πâ pattern ‡πÄ‡∏î‡∏¥‡∏°)
            old_pattern = f"script_{script_id}_{text_hash}_*.mp3"
            import glob
            for old_file in glob.glob(str(self.audio_dir / old_pattern)):
                try:
                    Path(old_file).unlink()
                    print(f"   üóëÔ∏è Removed old file: {Path(old_file).name}")
                except:
                    pass
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á TTS ‡∏î‡πâ‡∏ß‡∏¢ Edge TTS ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ SSML
            communicate = edge_tts.Communicate(cleaned_text, voice_name)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏Å‡πà‡∏≠‡∏ô
            temp_path = file_path.with_suffix('.tmp.mp3')
            await communicate.save(str(temp_path))
            
            print(f"   üéµ Edge TTS raw file generated: {temp_path.name}")
            
            # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ LAME Padding ‡πÅ‡∏•‡∏∞ Contamination
            if await self._fix_lame_padding_and_contamination(temp_path, file_path, script_title, emotion):
                print(f"   ‚úÖ Edge TTS generation completed (LAME padding fixed)")
                return str(file_path), web_url
            else:
                print(f"   ‚ùå LAME padding fix failed")
                raise Exception("LAME padding fix failed")
                
        except Exception as e:
            print(f"   ‚ùå Edge TTS failed: {e}")
            raise
    
    async def _fix_lame_padding_and_contamination(self, temp_path: Path, final_path: Path, script_title: str, emotion: str) -> bool:
        """‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ LAME Encoder Padding ‡πÅ‡∏•‡∏∞ Audio Contamination"""
        
        try:
            if not AUDIO_PROCESSING_AVAILABLE:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ audio processing ‡πÉ‡∏´‡πâ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á‡πÜ
                temp_path.rename(final_path)
                return True
            
            print(f"   üîß Fixing LAME padding and contamination...")
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            audio = AudioSegment.from_file(temp_path)
            original_duration = len(audio) / 1000
            
            print(f"   ‚è±Ô∏è Original duration: {original_duration:.1f}s")
            
            # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ LAME padding ‡πÅ‡∏•‡∏∞ contamination
            fixed_audio = self._remove_lame_padding_and_silence(audio)
            
            if fixed_audio:
                final_duration = len(fixed_audio) / 1000
                print(f"   ‚úÇÔ∏è Fixed duration: {final_duration:.1f}s (removed {original_duration - final_duration:.1f}s)")
                
                # Normalize ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
                fixed_audio = normalize(fixed_audio)
                fixed_audio = fixed_audio.set_frame_rate(22050)
                
                # Export ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ LAME encoder ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô padding
                fixed_audio.export(
                    final_path,
                    format="mp3",
                    bitrate="128k",
                    parameters=[
                        "-q:a", "2",           # ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á
                        "-ar", "22050",        # Sample rate
                        "-write_xing", "0",    # ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô XING header
                        "-id3v2_version", "0", # ‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà ID3v2 tags
                        "-write_id3v1", "0"    # ‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà ID3v1 tags
                    ]
                )
                
                # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
                if temp_path.exists():
                    temp_path.unlink()
                
                print(f"   üéØ LAME padding and contamination removed successfully")
                return True
            else:
                print(f"   ‚ùå Could not fix LAME padding")
                # ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
                temp_path.rename(final_path)
                return True
                
        except Exception as e:
            print(f"   ‚ùå LAME padding fix failed: {e}")
            
            # ‡∏´‡∏≤‡∏Å‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÉ‡∏´‡πâ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
            try:
                if temp_path.exists():
                    temp_path.rename(final_path)
                return True
            except:
                return False

    def _remove_lame_padding_and_silence(self, audio: 'AudioSegment') -> 'AudioSegment':
        """‡∏Å‡∏≥‡∏à‡∏±‡∏î LAME padding ‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£"""
        
        try:
            print(f"   üîç Analyzing audio for padding and silence...")
            
            # Parameters ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            silence_threshold = -50  # dB
            chunk_size = 100  # ms
            min_silence_duration = 500  # ms
            
            # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á (‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏ï‡πâ‡∏ô)
            start_pos = 0
            for i in range(0, len(audio), chunk_size):
                chunk = audio[i:i + chunk_size]
                if len(chunk) < chunk_size:
                    break
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì volume level
                if hasattr(chunk, 'dBFS'):
                    volume = chunk.dBFS
                else:
                    volume = chunk.rms if hasattr(chunk, 'rms') else -60
                
                if volume > silence_threshold:
                    start_pos = max(0, i - chunk_size)  # ‡πÄ‡∏Å‡πá‡∏ö buffer ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
                    print(f"   üéØ Found audio start at: {start_pos/1000:.1f}s")
                    break
            
            # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á (‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏ó‡πâ‡∏≤‡∏¢)
            end_pos = len(audio)
            for i in range(len(audio) - chunk_size, 0, -chunk_size):
                chunk = audio[i:i + chunk_size]
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì volume level
                if hasattr(chunk, 'dBFS'):
                    volume = chunk.dBFS
                else:
                    volume = chunk.rms if hasattr(chunk, 'rms') else -60
                
                if volume > silence_threshold:
                    end_pos = min(len(audio), i + chunk_size * 2)  # ‡πÄ‡∏Å‡πá‡∏ö buffer ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
                    print(f"   üéØ Found audio end at: {end_pos/1000:.1f}s")
                    break
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
            trimmed_duration = (end_pos - start_pos) / 1000
            
            if trimmed_duration < 0.5:
                print(f"   ‚ö†Ô∏è Trimmed audio too short ({trimmed_duration:.1f}s), using minimal trim")
                # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡πÅ‡∏ö‡∏ö‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
                start_pos = min(start_pos, len(audio) * 0.1)  # ‡∏ï‡∏±‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 10% ‡∏ï‡πâ‡∏ô
                end_pos = max(end_pos, len(audio) * 0.9)      # ‡∏ï‡∏±‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 10% ‡∏ó‡πâ‡∏≤‡∏¢
            
            elif trimmed_duration > 30:
                print(f"   ‚ö†Ô∏è Trimmed audio still too long ({trimmed_duration:.1f}s), applying aggressive trim")
                # ‡∏´‡∏≤‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
                max_volume = -100
                best_start = 0
                best_end = len(audio)
                
                # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏∏‡∏Å 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                window_size = 5000  # 5 seconds
                for i in range(int(start_pos), int(end_pos) - window_size, 1000):
                    window = audio[i:i + window_size]
                    if hasattr(window, 'dBFS'):
                        volume = window.dBFS
                    else:
                        volume = window.rms if hasattr(window, 'rms') else -60
                    
                    if volume > max_volume:
                        max_volume = volume
                        best_start = i
                        best_end = i + window_size
                
                start_pos = best_start
                end_pos = best_end
                print(f"   ‚úÇÔ∏è Using aggressive trim: {start_pos/1000:.1f}s to {end_pos/1000:.1f}s")
            
            # ‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            if start_pos > 0 or end_pos < len(audio):
                trimmed_audio = audio[start_pos:end_pos]
                print(f"   ‚úÖ Trimmed from {len(audio)/1000:.1f}s to {len(trimmed_audio)/1000:.1f}s")
                return trimmed_audio
            else:
                print(f"   ‚ÑπÔ∏è No trimming needed")
                return audio
                
        except Exception as e:
            print(f"   ‚ùå Padding removal failed: {e}")
            return audio

    def _clean_text_for_tts(self, text: str) -> str:
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ TTS ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô contamination"""
        
        # ‡∏•‡∏ö characters ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        import re
        
        # ‡∏•‡∏ö HTML tags
        text = re.sub(r'<[^>]+>', '', text)
        
        # ‡∏•‡∏ö special characters ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ TTS ‡∏™‡∏±‡∏ö‡∏™‡∏ô
        text = re.sub(r'[^\u0E00-\u0E7Fa-zA-Z0-9\s\.,!?\-]', '', text)
        
        # ‡∏•‡∏ö multiple spaces
        text = re.sub(r'\s+', ' ', text)
        
        # ‡∏•‡∏ö leading/trailing spaces
        text = text.strip()
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô buffer overflow
        if len(text) > 1000:
            text = text[:1000] + "..."
        
        return text

    def _create_safe_ssml(self, text: str, voice_name: str, emotion: str, intensity: float) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á SSML ‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ - ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô contamination"""
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà Edge TTS ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô
        safe_emotions = {
            "excited": "cheerful",
            "happy": "cheerful", 
            "professional": "neutral",  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å serious ‡πÄ‡∏õ‡πá‡∏ô neutral
            "friendly": "gentle",
            "confident": "neutral",     # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å serious ‡πÄ‡∏õ‡πá‡∏ô neutral
            "energetic": "cheerful",
            "calm": "gentle",
            "urgent": "neutral"         # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å angry ‡πÄ‡∏õ‡πá‡∏ô neutral
        }
        
        ssml_emotion = safe_emotions.get(emotion, "neutral")
        
        # ‡πÉ‡∏ä‡πâ SSML ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
        if ssml_emotion == "neutral":
            # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ express-as ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö neutral
            ssml = f"""<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="th-TH">
        <voice name="{voice_name}">
            <prosody rate="medium" pitch="medium">
                {text}
            </prosody>
        </voice>
    </speak>"""
        else:
            # ‡πÉ‡∏ä‡πâ express-as ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢
            ssml = f"""<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="th-TH">
        <voice name="{voice_name}">
            <mstts:express-as style="{ssml_emotion}">
                {text}
            </mstts:express-as>
        </voice>
    </speak>"""
        
        return ssml.strip()

    async def _validate_and_clean_audio(self, temp_path: Path, final_path: Path, script_title: str, emotion: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏à‡∏±‡∏î contamination"""
        
        try:
            if not AUDIO_PROCESSING_AVAILABLE:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ audio processing ‡πÉ‡∏´‡πâ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á‡πÜ
                temp_path.rename(final_path)
                return True
            
            print(f"   üîç Validating and cleaning audio...")
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            audio = AudioSegment.from_file(temp_path)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÑ‡∏ü‡∏•‡πå
            duration_ms = len(audio)
            print(f"   ‚è±Ô∏è Original duration: {duration_ms/1000:.1f}s")
            
            # ‡∏´‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ) ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ contamination
            if duration_ms > 30000:  # 30 seconds
                print(f"   ‚ö†Ô∏è Audio too long ({duration_ms/1000:.1f}s), attempting to extract main content...")
                
                # ‡∏´‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏á‡∏µ‡∏¢‡∏ö)
                # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÜ ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå volume
                chunk_size = 1000  # 1 second chunks
                chunks = []
                
                for i in range(0, len(audio), chunk_size):
                    chunk = audio[i:i+chunk_size]
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RMS (volume level)
                    rms = chunk.rms if hasattr(chunk, 'rms') else 100
                    chunks.append((i, rms))
                
                # ‡∏´‡∏≤‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á (RMS > threshold)
                threshold = max([chunk[1] for chunk in chunks]) * 0.1  # 10% ‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏±‡∏á‡∏™‡∏∏‡∏î
                active_chunks = [chunk for chunk in chunks if chunk[1] > threshold]
                
                if active_chunks:
                    # ‡∏ï‡∏±‡∏î‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á
                    start_time = min([chunk[0] for chunk in active_chunks])
                    end_time = max([chunk[0] for chunk in active_chunks]) + chunk_size
                    
                    # ‡πÄ‡∏û‡∏¥‡πà‡∏° buffer ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
                    start_time = max(0, start_time - 500)  # 0.5s buffer
                    end_time = min(len(audio), end_time + 500)  # 0.5s buffer
                    
                    audio = audio[start_time:end_time]
                    print(f"   ‚úÇÔ∏è Trimmed to: {len(audio)/1000:.1f}s (removed contamination)")
            
            # Normalize ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
            audio = normalize(audio)
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ sample rate ‡πÅ‡∏•‡∏∞ bitrate ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
            audio = audio.set_frame_rate(22050)
            
            # Export ‡πÄ‡∏õ‡πá‡∏ô MP3 ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ
            audio.export(
                final_path, 
                format="mp3", 
                bitrate="128k",
                parameters=["-q:a", "2", "-ar", "22050"]
            )
            
            # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            if temp_path.exists():
                temp_path.unlink()
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata
            self._clean_metadata(final_path, script_title, emotion)
            
            print(f"   ‚úÖ Audio validated and cleaned: {len(audio)/1000:.1f}s")
            return True
            
        except Exception as e:
            print(f"   ‚ùå Audio validation failed: {e}")
            
            # ‡∏´‡∏≤‡∏Å‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÉ‡∏´‡πâ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
            try:
                if temp_path.exists():
                    temp_path.rename(final_path)
                return True
            except:
                return False


    async def _generate_elevenlabs_speech(
        self, 
        text: str, 
        script_id: str, 
        voice_config: Dict, 
        emotion: str, 
        intensity: float,
        script_title: str = ""
    ) -> Tuple[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ ElevenLabs AI"""
        
        try:
            voice_id = voice_config.get("voice_id", "pNInz6obpgDQGcFmaJgB")
            
            # ‡∏õ‡∏£‡∏±‡∏ö text ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
            emotional_text = self._add_emotional_context(text, emotion, intensity)
            
            filename = f"script_{script_id}_{hashlib.md5(text.encode()).hexdigest()[:8]}.mp3"
            file_path = self.audio_dir / filename
            web_url = f"/static/audio/{filename}"
            
            print(f"   ü§ñ Using ElevenLabs voice: {voice_id}")
            print(f"   üìÅ Output: {file_path}")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á audio
            audio = generate(
                text=emotional_text,
                voice=voice_id,
                model="eleven_multilingual_v2"
            )
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
            with open(file_path, "wb") as f:
                f.write(audio)
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata
            await self._enhance_audio_quality(file_path, script_title, emotion)
            
            print(f"   ‚úÖ ElevenLabs generation completed")
            return str(file_path), web_url
            
        except Exception as e:
            print(f"   ‚ùå ElevenLabs failed: {e}")
            raise
    
    async def _generate_azure_speech(
        self, 
        text: str, 
        script_id: str, 
        voice_config: Dict, 
        emotion: str, 
        intensity: float,
        script_title: str = ""
    ) -> Tuple[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Azure Cognitive Services"""
        
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á Azure Speech config
            speech_config = speechsdk.SpeechConfig(
                subscription=self.azure_speech_key, 
                region=self.azure_speech_region
            )
            
            voice_name = voice_config.get("voice", "th-TH-PremwadeeNeural")
            speech_config.speech_synthesis_voice_name = voice_name
            
            filename = f"script_{script_id}_{hashlib.md5(text.encode()).hexdigest()[:8]}.wav"
            file_path = self.audio_dir / filename
            web_url = f"/static/audio/{filename}"
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á SSML ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
            ssml_text = self._create_emotional_ssml(text, voice_name, emotion, intensity)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á synthesizer
            audio_config = speechsdk.audio.AudioOutputConfig(filename=str(file_path))
            synthesizer = speechsdk.SpeechSynthesizer(
                speech_config=speech_config, 
                audio_config=audio_config
            )
            
            # ‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            result = synthesizer.speak_ssml_async(ssml_text).get()
            
            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô MP3 ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata
                mp3_path = await self._convert_to_mp3(file_path, script_title, emotion)
                print(f"   ‚úÖ Azure Speech generation completed")
                return str(mp3_path), web_url.replace('.wav', '.mp3')
            else:
                raise Exception(f"Azure synthesis failed: {result.reason}")
                
        except Exception as e:
            print(f"   ‚ùå Azure Speech failed: {e}")
            raise
    
    def _create_emotional_ssml(self, text: str, voice_name: str, emotion: str, intensity: float) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á SSML ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö SSML
        emotion_mapping = {
            "excited": "cheerful",
            "happy": "cheerful", 
            "professional": "serious",
            "friendly": "gentle",
            "confident": "serious",
            "energetic": "cheerful",
            "calm": "gentle",
            "urgent": "angry"
        }
        
        ssml_emotion = emotion_mapping.get(emotion, emotion)
        
        # ‡∏õ‡∏£‡∏±‡∏ö intensity
        intensity_level = "strong" if intensity > 1.5 else "moderate" if intensity > 1.0 else "mild"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á SSML
        ssml = f"""
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="th-TH">
            <voice name="{voice_name}">
                <mstts:express-as style="{ssml_emotion}" styledegree="{intensity}">
                    <prosody rate="{self._get_prosody_rate(emotion)}" pitch="{self._get_prosody_pitch(emotion)}">
                        {text}
                    </prosody>
                </mstts:express-as>
            </voice>
        </speak>
        """
        
        return ssml.strip()
    
    def _get_prosody_rate(self, emotion: str) -> str:
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        rates = {
            "excited": "+20%",
            "energetic": "+15%", 
            "urgent": "+25%",
            "calm": "-10%",
            "professional": "+5%",
            "friendly": "+10%"
        }
        return rates.get(emotion, "medium")
    
    def _get_prosody_pitch(self, emotion: str) -> str:
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        pitches = {
            "excited": "+15%",
            "happy": "+10%",
            "energetic": "+12%",
            "sad": "-15%",
            "calm": "-5%",
            "professional": "medium",
            "confident": "+8%"
        }
        return pitches.get(emotion, "medium")
    
    def _add_emotional_context(self, text: str, emotion: str, intensity: float) -> str:
        """‡πÄ‡∏û‡∏¥‡πà‡∏° emotional context ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI voices"""
        
        emotion_prefixes = {
            "excited": "‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ï‡∏∑‡∏≠‡∏£‡∏∑‡∏≠‡∏£‡πâ‡∏ô: ",
            "happy": "‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏î‡∏µ: ",
            "professional": "‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏ä‡∏µ‡∏û: ",
            "friendly": "‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô: ",
            "confident": "‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡πà‡∏ß‡πÅ‡∏ô‡πà: ",
            "energetic": "‡∏î‡πâ‡∏ß‡∏¢‡∏û‡∏•‡∏±‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏£‡∏∞‡∏õ‡∏£‡∏µ‡πâ‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡∏£‡πà‡∏≤: ",
            "calm": "‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏á‡∏ö‡πÅ‡∏•‡∏∞‡πÉ‡∏à‡πÄ‡∏¢‡πá‡∏ô: ",
            "urgent": "‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤: "
        }
        
        prefix = emotion_prefixes.get(emotion, "")
        return f"{prefix}{text}" if prefix else text
    
    async def _convert_to_mp3(self, wav_path: Path, script_title: str = "", emotion: str = "") -> Path:
        """‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå WAV ‡πÄ‡∏õ‡πá‡∏ô MP3 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata"""
        try:
            if not AUDIO_PROCESSING_AVAILABLE:
                return wav_path
                
            mp3_path = wav_path.with_suffix('.mp3')
            audio = AudioSegment.from_wav(wav_path)
            
            # Export ‡πÄ‡∏õ‡πá‡∏ô MP3 ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ
            audio.export(
                mp3_path, 
                format="mp3", 
                bitrate="128k",
                parameters=["-q:a", "2"]
            )
            
            # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå WAV
            if wav_path.exists():
                wav_path.unlink()
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata
            self._clean_metadata(mp3_path, script_title, emotion)
                
            return mp3_path
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è MP3 conversion failed: {e}")
            return wav_path
    
    def _get_best_available_provider(self) -> str:
        """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å provider ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà"""
        try:
            # ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£: edge > elevenlabs > azure > basic
            priority_order = ["edge", "elevenlabs", "azure", "basic"]
            
            for provider in priority_order:
                if (provider in self.providers and 
                    self.providers[provider].get("available", False)):
                    print(f"   üéØ Selected provider: {provider}")
                    return provider
            
            # ‡∏´‡∏≤‡∏Å providers ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ basic
            print("   ‚ö†Ô∏è No enhanced providers available, using basic fallback")
            return "basic"
            
        except Exception as e:
            print(f"   ‚ùå Error selecting provider: {e}")
            return "basic"
    
    async def _generate_basic_speech(self, text: str, script_id: str, language: str = "th", script_title: str = "") -> Tuple[str, str]:
        """Fallback ‡πÄ‡∏õ‡πá‡∏ô basic gTTS ‡∏û‡∏£‡πâ‡∏≠‡∏° unique filename"""
        try:
            if not GTTS_AVAILABLE:
                print("   ‚ùå gTTS not available for fallback")
                return "", ""
            
            import time
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            cleaned_text = self._clean_text_for_tts(text) if hasattr(self, '_clean_text_for_tts') else text
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á unique filename
            timestamp = str(int(time.time() * 1000))
            text_hash = hashlib.md5(cleaned_text.encode()).hexdigest()[:8]
            filename = f"script_{script_id}_{text_hash}_{timestamp}.mp3"
            
            file_path = self.audio_dir / filename
            web_url = f"/static/audio/{filename}"
            
            print(f"   üì¢ Using basic gTTS")
            print(f"   üìÅ Unique filename: {filename}")
            print(f"   üßπ Text: '{cleaned_text[:30]}...'")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢ gTTS
            tts = gTTS(text=cleaned_text, lang=language, slow=False)
            tts.save(str(file_path))
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î metadata ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
            if hasattr(self, '_clean_metadata'):
                try:
                    self._clean_metadata(file_path, script_title or "Basic TTS Audio", "neutral")
                except:
                    pass
            
            print(f"   ‚úÖ Basic gTTS generation completed")
            return str(file_path), web_url
            
        except Exception as e:
            print(f"   ‚ùå Basic TTS failed: {e}")
            return "", ""
    
    def is_enhanced_available(self) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Enhanced TTS ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        enhanced_providers = ["edge", "elevenlabs", "azure"]
        return any(self.providers.get(p, {}).get("available", False) for p in enhanced_providers)

    def get_recommended_provider(self) -> str:
        """‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ provider ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
        if self.providers.get("edge", {}).get("available", False):
            return "edge"
        elif self.providers.get("elevenlabs", {}).get("available", False):
            return "elevenlabs"
        elif self.providers.get("azure", {}).get("available", False):
            return "azure"
        else:
            return "basic"

    def get_provider_status(self) -> Dict[str, Any]:
        """‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á providers ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        status = {}
        for provider, config in self.providers.items():
            status[provider] = {
                "available": config.get("available", False),
                "quality": config.get("quality", "unknown"),
                "cost": config.get("cost", "unknown"),
                "voice_count": len(config.get("voices", {})),
                "supports_emotions": config.get("supports_emotions", False)
            }
        return status

    # ‡πÄ‡∏°‡∏ò‡∏≠‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö compatibility ‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°
    async def generate_script_audio(
        self,
        script_id: str,
        content: str,
        language: str = "th",
        voice_persona: Optional[Dict] = None
    ) -> Tuple[str, str]:
        """Generate audio for script - compatible with existing system ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß"""
        
        try:
            print(f"üéµ Generating audio for script {script_id}")
            
            # Parse voice persona config safely
            script_title = f"Script {script_id}"  # Default title
            if voice_persona:
                provider = voice_persona.get("tts_provider", "edge")
                emotion = voice_persona.get("emotion", "professional")
                voice_config = {
                    "voice": voice_persona.get("voice_id", "th-TH-PremwadeeNeural"),
                    "voice_id": voice_persona.get("voice_id", "pNInz6obpgDQGcFmaJgB")
                }
                intensity = voice_persona.get("emotional_intensity", 1.0)
                # ‡∏î‡∏∂‡∏á script title ‡∏à‡∏≤‡∏Å voice_persona ‡∏´‡∏≤‡∏Å‡∏°‡∏µ
                script_title = voice_persona.get("script_title", script_title)
            else:
                provider = self.get_recommended_provider()
                emotion = "professional"
                voice_config = {"voice": "th-TH-PremwadeeNeural"}
                intensity = 1.0
            
            print(f"   üé≠ Using provider: {provider}")
            print(f"   üó£Ô∏è Voice config: {voice_config}")
            print(f"   üé≠ Emotion: {emotion}")
            print(f"   üè∑Ô∏è Title: {script_title}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ provider ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
            if not self.providers.get(provider, {}).get("available", False):
                print(f"   ‚ö†Ô∏è Provider {provider} not available, switching to best available")
                provider = self._get_best_available_provider()
            
            # ‡πÉ‡∏ä‡πâ enhanced generation ‡∏´‡∏≤‡∏Å‡∏°‡∏µ
            if hasattr(self, 'generate_emotional_speech') and provider != "basic":
                return await self.generate_emotional_speech(
                    text=content,
                    script_id=script_id,
                    provider=provider,
                    voice_config=voice_config,
                    emotion=emotion,
                    intensity=intensity,
                    language=language,
                    script_title=script_title  # ‡∏™‡πà‡∏á title ‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢
                )
            else:
                # ‡πÉ‡∏ä‡πâ basic fallback
                print(f"   üì¢ Using basic fallback for {provider}")
                return await self._generate_basic_speech(content, script_id, language, script_title)
                
        except Exception as e:
            print(f"‚ùå Error in generate_script_audio: {e}")
            # Ultimate fallback
            try:
                return await self._generate_basic_speech(content, script_id, language, "Script Audio")
            except Exception as fallback_error:
                print(f"‚ùå Even fallback failed: {fallback_error}")
                return "", ""
    
    def get_available_providers(self) -> Dict[str, Any]:
        """‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ providers ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ"""
        return {
            provider: {
                "available": config["available"],
                "voices": config["voices"],
                "supports_emotions": config["supports_emotions"],
                "quality": config["quality"],
                "cost": config["cost"]
            }
            for provider, config in self.providers.items()
        }
    
    def get_emotions_for_provider(self, provider: str) -> list:
        """‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà provider ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö"""
        if provider == "edge":
            return ["cheerful", "sad", "angry", "fearful", "disgruntled", "serious", "affectionate", "gentle", "envious"]
        elif provider == "elevenlabs":
            return ["neutral", "excited", "sad", "angry", "cheerful", "serious", "gentle"]
        elif provider == "azure":
            return ["cheerful", "sad", "angry", "fearful", "serious", "gentle"]
        else:
            return ["neutral"]

# ‡∏™‡∏£‡πâ‡∏≤‡∏á global instance
enhanced_tts_service = EnhancedTTSService()